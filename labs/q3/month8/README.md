# Quarter 3, Month 8: Advanced Adversarial Attacks & Generative AI Threats

## Overview

This month covers advanced adversarial attacks including data poisoning and explores threats from generative AI such as deepfakes and AI-generated malware.

## Lab Assignments

### Lab 9: Executing a Data Poisoning Attack (Weeks 29-30)

Implement a data poisoning attack by injecting mislabeled data into a training set to degrade model performance.

**Topics Covered:**
- Data poisoning attack techniques
- Training data corruption
- Model performance degradation
- Defense mechanisms

**Deliverables:**
- Python implementation
- Performance comparison
- Lab report with analysis

**Grading:** 100 points

### Lab 10: Building and Detecting Deepfake Videos (Weeks 31-32)

Generate deepfake videos using AI techniques and implement detection mechanisms.

**Topics Covered:**
- Deepfake generation techniques
- Deepfake detection methods
- Forensic analysis of manipulated media
- Implications for security

**Deliverables:**
- Deepfake generation code
- Detection implementation
- Lab report with analysis

**Grading:** 100 points

See [lab9_data_poisoning_attack.md](lab9_data_poisoning_attack.md) and [lab10_deepfake_detection.md](lab10_deepfake_detection.md) for complete details.

## Learning Outcomes

Upon completion of this month, students will be able to:

- Implement data poisoning attacks
- Generate and detect deepfakes
- Understand threats from generative AI
- Develop defenses against advanced attacks

## Resources

- Data Poisoning: https://arxiv.org/abs/1206.6389
- Deepfakes: https://github.com/ondyari/FaceForensics
- Generative AI: https://openai.com/research/
