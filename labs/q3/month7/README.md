# Quarter 3, Month 7: Introduction to Adversarial AI & Evasion Attacks

## Overview

This month introduces adversarial AI and evasion attacks against machine learning models. Students research real-world adversarial attacks and implement evasion techniques.

## Lab Assignments

### Lab 7: Research and Presentation on Recent Adversarial Attacks (Weeks 25-26)

Conduct in-depth research on a real-world adversarial attack and present findings to the class.

**Topics Covered:**
- Taxonomy of adversarial attacks
- Real-world attack case studies
- Defense mechanisms
- Research and presentation skills

**Deliverables:**
- Research paper (5-7 pages)
- Presentation slides
- Group presentation

**Grading:** 100 points

### Lab 8: Bypassing a Malware Classifier with an Evasion Attack (Weeks 27-28)

Implement the Fast Gradient Sign Method (FGSM) to generate adversarial examples that bypass a malware classifier.

**Topics Covered:**
- Evasion attack techniques
- FGSM algorithm
- Adversarial example generation
- Model robustness evaluation

**Deliverables:**
- Python implementation
- Adversarial examples
- Lab report with analysis

**Grading:** 100 points

See [lab7_adversarial_attack_research.md](lab7_adversarial_attack_research.md) and [lab8_evasion_attack.md](lab8_evasion_attack.md) for complete details.

## Learning Outcomes

Upon completion of this month, students will be able to:

- Understand the taxonomy of adversarial attacks
- Implement evasion attacks against ML models
- Evaluate model robustness
- Conduct research on adversarial AI threats

## Resources

- Adversarial Examples: https://arxiv.org/abs/1312.6199
- FGSM: https://arxiv.org/abs/1412.6572
- ART Toolbox: https://github.com/Trusted-AI/adversarial-robustness-toolbox
