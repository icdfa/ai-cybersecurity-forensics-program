# Lab 3: Building an Intelligent Malware Detection System

## Quarter 1, Month 3, Weeks 9-12

### Objective

This lab is the mini-project for Quarter 1. You will build an end-to-end malware detection system using machine learning. You will handle a larger, more realistic dataset, perform feature engineering, train multiple models, and select the best one for deployment. This project will integrate the skills you have learned throughout the first quarter.

### Learning Outcomes

Upon completion of this lab, you will be able to:

-   Process and prepare a large-scale dataset for malware analysis.
-   Engineer and select relevant features for malware classification.
-   Train, evaluate, and compare multiple machine learning models.
-   Fine-tune a model for optimal performance.
-   Develop a complete, functional malware detection tool.

### Prerequisites

-   Completion of all previous labs in Quarter 1.
-   A strong understanding of Python, Pandas, and Scikit-learn.
-   Familiarity with the fundamentals of malware analysis.

### Required Tools and Libraries

```bash
pip install scikit-learn pandas numpy matplotlib seaborn
```

### Dataset

This lab will use a comprehensive dataset of malware and benign software samples. The dataset will be provided and will include a large number of PE file features.

### Part 1: Data Loading and Exploratory Data Analysis (EDA)

**Objective:** Load the dataset and perform an initial analysis to understand its characteristics.

**Step 1: Load the Data**

```python
import pandas as pd

# Load the dataset
data = pd.read_csv("malware_dataset.csv") # A comprehensive dataset will be provided

# Display the first few rows and basic info
print(data.head())
print(data.info())
print(data["label"].value_counts())
```

**Step 2: Exploratory Data Analysis**

-   Visualize the distribution of malware vs. benign samples.
-   Analyze the correlations between different features.

```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x="label", data=data)
plt.title("Distribution of Malware vs. Benign Samples")
plt.show()

# Correlation matrix (for a subset of features)
plt.figure(figsize=(12, 10))
sns.heatmap(data.iloc[:, :15].corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation Matrix")
plt.show()
```

### Part 2: Feature Engineering and Selection

**Objective:** Select the most relevant features for building a high-performance model.

**Step 1: Feature Selection**

Use a technique like `SelectKBest` to identify the most important features.

```python
from sklearn.feature_selection import SelectKBest, chi2

X = data.drop("label", axis=1)
y = data["label"]

# Select the top 50 features
selector = SelectKBest(chi2, k=50)
X_new = selector.fit_transform(X, y)

# Get the names of the selected features
selected_features = X.columns[selector.get_support()]
print("Selected features:", selected_features)
```

### Part 3: Model Training and Evaluation

**Objective:** Train and evaluate multiple classification models to find the best performer.

**Step 1: Train Multiple Models**

Train models like Logistic Regression, Random Forest, and Gradient Boosting.

```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

models = {
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"--- {name} ---")
    print(classification_report(y_test, y_pred))
```

### Part 4: Model Tuning and Finalization

**Objective:** Fine-tune the best model to optimize its performance.

**Step 1: Hyperparameter Tuning**

Use `GridSearchCV` to find the best hyperparameters for your chosen model.

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    "n_estimators": [100, 200, 300],
    "max_depth": [10, 20, 30]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)

# Evaluate the tuned model
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)
print(classification_report(y_test, y_pred))
```

### Deliverables

1.  **Jupyter Notebook:** A complete Jupyter Notebook containing all your code, analysis, and visualizations.
2.  **Final Model:** The saved, trained model file (e.g., in `.pkl` format).
3.  **Project Report:** A 3-5 page report detailing:
    *   Your EDA findings.
    *   The feature engineering and selection process.
    *   A comparison of the different models you trained.
    *   The results of your hyperparameter tuning.
    *   A conclusion on the effectiveness of your final model.

### Grading Rubric

| Criterion | Points | Description |
| :--- | :--- | :--- |
| Data Analysis (EDA) | 20 | Thorough and insightful exploratory data analysis. |
| Feature Engineering | 20 | Effective feature selection and justification. |
| Model Training & Comparison | 30 | Correctly trains and evaluates multiple models, with a clear comparison. |
| Model Tuning | 20 | Properly implements hyperparameter tuning to improve performance. |
| Report and Code Quality | 10 | A well-written report and clean, well-documented code. |
| **Total** | **100** | |
