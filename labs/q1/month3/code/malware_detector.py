#!/usr/bin/env python3
"""
Lab 3: Intelligent Malware Detection System
Advanced AI in Cybersecurity and Digital Forensics Program

This script builds a machine learning-based malware detection system.

Author: Manus AI
Date: January 2026
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import argparse
import json
from datetime import datetime

class MalwareDetector:
    """Intelligent Malware Detection System"""
    
    def __init__(self):
        """Initialize the malware detector"""
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        self.model_type = None
    
    def load_data(self, data_path, sample_size=None):
        """
        Load malware dataset
        
        Args:
            data_path (str): Path to dataset CSV file
            sample_size (int): Number of samples to load (None for all)
        
        Returns:
            tuple: X (features), y (labels)
        """
        print(f"[*] Loading dataset from: {data_path}")
        
        df = pd.read_csv(data_path)
        
        if sample_size:
            df = df.sample(n=min(sample_size, len(df)), random_state=42)
        
        print(f"[+] Loaded {len(df)} samples")
        
        # Separate features and labels
        if 'label' in df.columns:
            y = df['label']
            X = df.drop('label', axis=1)
        elif 'is_malware' in df.columns:
            y = df['is_malware']
            X = df.drop('is_malware', axis=1)
        else:
            raise ValueError("Dataset must have 'label' or 'is_malware' column")
        
        self.feature_names = X.columns.tolist()
        
        print(f"[+] Features: {len(self.feature_names)}")
        print(f"[+] Malware samples: {sum(y == 1)}")
        print(f"[+] Benign samples: {sum(y == 0)}")
        
        return X, y
    
    def preprocess_data(self, X_train, X_test):
        """
        Preprocess features (scaling)
        
        Args:
            X_train: Training features
            X_test: Test features
        
        Returns:
            tuple: Scaled X_train, X_test
        """
        print("[*] Preprocessing data...")
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        print("[+] Data preprocessing complete")
        
        return X_train_scaled, X_test_scaled
    
    def train_model(self, X_train, y_train, model_type='random_forest'):
        """
        Train malware detection model
        
        Args:
            X_train: Training features
            y_train: Training labels
            model_type (str): Type of model ('random_forest', 'gradient_boosting', 'logistic', 'svm')
        """
        print(f"[*] Training {model_type} model...")
        
        self.model_type = model_type
        
        if model_type == 'random_forest':
            self.model = RandomForestClassifier(
                n_estimators=100,
                max_depth=20,
                random_state=42,
                n_jobs=-1
            )
        elif model_type == 'gradient_boosting':
            self.model = GradientBoostingClassifier(
                n_estimators=100,
                max_depth=5,
                random_state=42
            )
        elif model_type == 'logistic':
            self.model = LogisticRegression(
                max_iter=1000,
                random_state=42,
                n_jobs=-1
            )
        elif model_type == 'svm':
            self.model = SVC(
                kernel='rbf',
                probability=True,
                random_state=42
            )
        else:
            raise ValueError(f"Unknown model type: {model_type}")
        
        # Train model
        self.model.fit(X_train, y_train)
        
        print("[+] Model training complete")
    
    def evaluate_model(self, X_test, y_test):
        """
        Evaluate model performance
        
        Args:
            X_test: Test features
            y_test: Test labels
        
        Returns:
            dict: Evaluation metrics
        """
        print("[*] Evaluating model...")
        
        # Make predictions
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)[:, 1]
        
        # Calculate metrics
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1_score': f1_score(y_test, y_pred),
            'roc_auc': roc_auc_score(y_test, y_pred_proba)
        }
        
        print("\n" + "=" * 60)
        print("MODEL EVALUATION RESULTS")
        print("=" * 60)
        print(f"Accuracy:  {metrics['accuracy']:.4f}")
        print(f"Precision: {metrics['precision']:.4f}")
        print(f"Recall:    {metrics['recall']:.4f}")
        print(f"F1-Score:  {metrics['f1_score']:.4f}")
        print(f"ROC-AUC:   {metrics['roc_auc']:.4f}")
        print()
        
        # Print classification report
        print("Classification Report:")
        print(classification_report(y_test, y_pred, 
                                   target_names=['Benign', 'Malware']))
        
        # Print confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        print("\nConfusion Matrix:")
        print(f"TN: {cm[0,0]}, FP: {cm[0,1]}")
        print(f"FN: {cm[1,0]}, TP: {cm[1,1]}")
        print()
        
        return metrics, y_pred, y_pred_proba
    
    def plot_roc_curve(self, y_test, y_pred_proba, save_path='roc_curve.png'):
        """
        Plot ROC curve
        
        Args:
            y_test: True labels
            y_pred_proba: Predicted probabilities
            save_path (str): Path to save plot
        """
        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
        roc_auc = roc_auc_score(y_test, y_pred_proba)
        
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, color='darkorange', lw=2, 
                label=f'ROC curve (AUC = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic (ROC) Curve')
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"[+] ROC curve saved to: {save_path}")
        plt.close()
    
    def plot_confusion_matrix(self, y_test, y_pred, save_path='confusion_matrix.png'):
        """
        Plot confusion matrix
        
        Args:
            y_test: True labels
            y_pred: Predicted labels
            save_path (str): Path to save plot
        """
        cm = confusion_matrix(y_test, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Benign', 'Malware'],
                   yticklabels=['Benign', 'Malware'])
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.title('Confusion Matrix')
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"[+] Confusion matrix saved to: {save_path}")
        plt.close()
    
    def get_feature_importance(self, top_n=20):
        """
        Get feature importance (for tree-based models)
        
        Args:
            top_n (int): Number of top features to return
        
        Returns:
            pd.DataFrame: Feature importance
        """
        if hasattr(self.model, 'feature_importances_'):
            importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            return importance.head(top_n)
        else:
            print("[-] Feature importance not available for this model type")
            return None
    
    def save_model(self, model_path='malware_detector.pkl'):
        """
        Save trained model to disk
        
        Args:
            model_path (str): Path to save model
        """
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'model_type': self.model_type,
            'timestamp': datetime.now().isoformat()
        }
        
        joblib.dump(model_data, model_path)
        print(f"[+] Model saved to: {model_path}")
    
    def load_model(self, model_path='malware_detector.pkl'):
        """
        Load trained model from disk
        
        Args:
            model_path (str): Path to model file
        """
        model_data = joblib.load(model_path)
        
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.feature_names = model_data['feature_names']
        self.model_type = model_data['model_type']
        
        print(f"[+] Model loaded from: {model_path}")
        print(f"[+] Model type: {self.model_type}")
        print(f"[+] Trained on: {model_data['timestamp']}")
    
    def predict(self, X):
        """
        Make predictions on new data
        
        Args:
            X: Features
        
        Returns:
            tuple: predictions, probabilities
        """
        X_scaled = self.scaler.transform(X)
        predictions = self.model.predict(X_scaled)
        probabilities = self.model.predict_proba(X_scaled)
        
        return predictions, probabilities

def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description="Malware Detection System - Lab 3",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Train a model
  python malware_detector.py --train --data malware_dataset.csv --model random_forest
  
  # Evaluate a trained model
  python malware_detector.py --evaluate --data malware_dataset.csv --load model.pkl
  
  # Compare multiple models
  python malware_detector.py --compare --data malware_dataset.csv
        """
    )
    
    parser.add_argument('--train', action='store_true', help='Train a model')
    parser.add_argument('--evaluate', action='store_true', help='Evaluate a model')
    parser.add_argument('--compare', action='store_true', help='Compare multiple models')
    parser.add_argument('--data', required=True, help='Path to dataset CSV file')
    parser.add_argument('--model', default='random_forest',
                       choices=['random_forest', 'gradient_boosting', 'logistic', 'svm'],
                       help='Model type')
    parser.add_argument('--save', default='malware_detector.pkl', 
                       help='Path to save model')
    parser.add_argument('--load', help='Path to load model')
    parser.add_argument('--sample-size', type=int, help='Number of samples to use')
    
    args = parser.parse_args()
    
    detector = MalwareDetector()
    
    if args.train:
        # Load data
        X, y = detector.load_data(args.data, args.sample_size)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Preprocess
        X_train_scaled, X_test_scaled = detector.preprocess_data(X_train, X_test)
        
        # Train
        detector.train_model(X_train_scaled, y_train, args.model)
        
        # Evaluate
        metrics, y_pred, y_pred_proba = detector.evaluate_model(X_test_scaled, y_test)
        
        # Plot results
        detector.plot_roc_curve(y_test, y_pred_proba)
        detector.plot_confusion_matrix(y_test, y_pred)
        
        # Feature importance
        importance = detector.get_feature_importance()
        if importance is not None:
            print("\nTop 10 Most Important Features:")
            print(importance.head(10).to_string(index=False))
        
        # Save model
        detector.save_model(args.save)
    
    elif args.evaluate:
        # Load model
        detector.load_model(args.load)
        
        # Load data
        X, y = detector.load_data(args.data, args.sample_size)
        
        # Preprocess
        X_scaled = detector.scaler.transform(X)
        
        # Evaluate
        metrics, y_pred, y_pred_proba = detector.evaluate_model(X_scaled, y)
        
        # Plot results
        detector.plot_roc_curve(y, y_pred_proba)
        detector.plot_confusion_matrix(y, y_pred)
    
    elif args.compare:
        print("[*] Comparing multiple models...")
        
        # Load data
        X, y = detector.load_data(args.data, args.sample_size)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Preprocess
        X_train_scaled, X_test_scaled = detector.preprocess_data(X_train, X_test)
        
        # Compare models
        models = ['random_forest', 'gradient_boosting', 'logistic']
        results = []
        
        for model_type in models:
            print(f"\n{'='*60}")
            print(f"Training {model_type}...")
            print('='*60)
            
            detector_temp = MalwareDetector()
            detector_temp.scaler = detector.scaler
            detector_temp.feature_names = detector.feature_names
            
            detector_temp.train_model(X_train_scaled, y_train, model_type)
            metrics, _, _ = detector_temp.evaluate_model(X_test_scaled, y_test)
            
            results.append({
                'model': model_type,
                **metrics
            })
        
        # Print comparison
        print("\n" + "=" * 80)
        print("MODEL COMPARISON")
        print("=" * 80)
        results_df = pd.DataFrame(results)
        print(results_df.to_string(index=False))

if __name__ == "__main__":
    main()
